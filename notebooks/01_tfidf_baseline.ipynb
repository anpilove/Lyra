{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF baseline\n",
    "\n",
    "Self-contained implementation and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8f22c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ../data/annotations_dataset_new.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "DATASET_PATH = Path('..') / 'data' / 'annotations_dataset_full.json'\n",
    "if not DATASET_PATH.exists():\n",
    "    DATASET_PATH = Path('..') / 'data' / 'annotations_dataset_new.json'\n",
    "print('Dataset:', DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342498ef",
   "metadata": {},
   "source": [
    "## Dataset stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e914ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs: 3291\n",
      "Annotations: 22220\n",
      "Avg annotations per song: 6.75\n"
     ]
    }
   ],
   "source": [
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "songs = len(data)\n",
    "annotations = sum(len(s.get('annotations', [])) for s in data)\n",
    "print('Songs:', songs)\n",
    "print('Annotations:', annotations)\n",
    "print('Avg annotations per song:', round(annotations / songs, 2) if songs else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c951d",
   "metadata": {},
   "source": [
    "## Load pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: 22220\n",
      "Using subset: 2000\n"
     ]
    }
   ],
   "source": [
    "fragments = []\n",
    "annotations = []\n",
    "metadata = []\n",
    "\n",
    "for song in data:\n",
    "    for ann in song.get('annotations', []):\n",
    "        fragments.append(ann.get('fragment', ''))\n",
    "        annotations.append(ann.get('annotation', ''))\n",
    "        metadata.append({\n",
    "            'artist': song.get('artist', ''),\n",
    "            'title': song.get('title', ''),\n",
    "            'votes': ann.get('votes', 0),\n",
    "        })\n",
    "\n",
    "print('Pairs:', len(fragments))\n",
    "\n",
    "MAX_EXAMPLES = 2000\n",
    "if MAX_EXAMPLES:\n",
    "    import random\n",
    "    idx = list(range(len(fragments)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(idx)\n",
    "    idx = idx[:MAX_EXAMPLES]\n",
    "    fragments = [fragments[i] for i in idx]\n",
    "    annotations = [annotations[i] for i in idx]\n",
    "    metadata = [metadata[i] for i in idx]\n",
    "    print('Using subset:', len(fragments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90285b1",
   "metadata": {},
   "source": [
    "## Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8dff862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "class TfidfRetriever:\n",
    "    def __init__(self, fragments, annotations, metadata):\n",
    "        self.fragments = fragments\n",
    "        self.annotations = annotations\n",
    "        self.metadata = metadata\n",
    "        self.vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2), lowercase=True)\n",
    "        self.fragment_vectors = self.vectorizer.fit_transform(self.fragments)\n",
    "\n",
    "    def find_similar(self, query, top_k=3):\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        sims = cosine_similarity(query_vec, self.fragment_vectors)[0]\n",
    "        top_indices = np.argsort(sims)[-top_k:][::-1]\n",
    "        return [\n",
    "            {\n",
    "                'fragment': self.fragments[idx],\n",
    "                'annotation': self.annotations[idx],\n",
    "                'similarity': float(sims[idx]),\n",
    "                'artist': self.metadata[idx]['artist'],\n",
    "                'title': self.metadata[idx]['title'],\n",
    "                'votes': self.metadata[idx]['votes'],\n",
    "            }\n",
    "            for idx in top_indices\n",
    "        ]\n",
    "\n",
    "def evaluate_tfidf(fragments, annotations, metadata):\n",
    "    retriever = TfidfRetriever(fragments, annotations, metadata)\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    similarities = []\n",
    "\n",
    "    for i, fragment in enumerate(fragments):\n",
    "        query_vec = retriever.vectorizer.transform([fragment])\n",
    "        sims = cosine_similarity(query_vec, retriever.fragment_vectors)[0]\n",
    "        sims[i] = -1e9\n",
    "        top_indices = np.argsort(sims)[-3:][::-1]\n",
    "\n",
    "        predicted = retriever.annotations[top_indices[0]]\n",
    "        true_annotation = annotations[i]\n",
    "\n",
    "        predictions.append(predicted)\n",
    "        references.append(true_annotation)\n",
    "        similarities.append(sims[top_indices[0]])\n",
    "\n",
    "        if predicted == true_annotation:\n",
    "            correct_top1 += 1\n",
    "        if true_annotation in [retriever.annotations[idx] for idx in top_indices]:\n",
    "            correct_top3 += 1\n",
    "\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "    bleu = corpus_bleu(predictions, [[r] for r in references])\n",
    "\n",
    "    return {\n",
    "        'method': 'TF-IDF',\n",
    "        'top1_accuracy': correct_top1 / len(fragments) if fragments else 0.0,\n",
    "        'top3_accuracy': correct_top3 / len(fragments) if fragments else 0.0,\n",
    "        'avg_similarity': float(np.mean(similarities)) if similarities else 0.0,\n",
    "        'rouge1': float(np.mean(rouge_scores['rouge1'])) if rouge_scores['rouge1'] else 0.0,\n",
    "        'rouge2': float(np.mean(rouge_scores['rouge2'])) if rouge_scores['rouge2'] else 0.0,\n",
    "        'rougeL': float(np.mean(rouge_scores['rougeL'])) if rouge_scores['rougeL'] else 0.0,\n",
    "        'bleu': bleu.score,\n",
    "        'total_examples': len(fragments),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d9c8f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path('..') / 'data' / 'evaluation_results.json'\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(tfidf_results, f, ensure_ascii=False, indent=2)\n",
    "print('Saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba84a09",
   "metadata": {},
   "source": [
    "## Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab60ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'TF-IDF Retrieval',\n",
       " 'top1_accuracy': 0.004,\n",
       " 'top3_accuracy': 0.01,\n",
       " 'avg_similarity': 0.55,\n",
       " 'rouge1': 0.007,\n",
       " 'rouge2': 0.0027,\n",
       " 'rougeL': 0.0062,\n",
       " 'bleu': 0.01,\n",
       " 'total_examples': 2000}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results = evaluate_tfidf(fragments, annotations, metadata)\n",
    "tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22425a",
   "metadata": {},
   "source": [
    "## Demo query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "344123af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fragment': 'Город под подошвой\\n Город под подошвой — этот город под подошвой',\n",
       "  'annotation': '«Город под подошвой» — песня российского рэпера Оксимирона (Oxxxymiron).',\n",
       "  'similarity': 0.7662352075088681,\n",
       "  'artist': 'CMH',\n",
       "  'title': 'GAZZ',\n",
       "  'votes': 3},\n",
       " {'fragment': 'Город «А», город «Z»',\n",
       "  'annotation': 'Буквы, которыми обозначали два крупнейших города Казахстана на номерных знаках автомобилей:\\n\\nА – Алматы\\nZ – Астана\\n\\nqurt коренной Астанчанин, но в данный момент проживает и развивается в южной столице – Алматы.',\n",
       "  'similarity': 0.6184510634570308,\n",
       "  'artist': '104',\n",
       "  'title': 'КОПЕР (COPER)',\n",
       "  'votes': 4}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = TfidfRetriever(fragments, annotations, metadata)\n",
    "retriever.find_similar('Я вижу город под подошвой', top_k=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
