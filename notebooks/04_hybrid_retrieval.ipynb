{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid retrieval\n",
    "\n",
    "Self-contained implementation and evaluation. GPU recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ../data/annotations_dataset_new.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "DATASET_PATH = Path('..') / 'data' / 'annotations_dataset_full.json'\n",
    "if not DATASET_PATH.exists():\n",
    "    DATASET_PATH = Path('..') / 'data' / 'annotations_dataset_new.json'\n",
    "print('Dataset:', DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs: 3291\n",
      "Annotations: 22220\n",
      "Avg annotations per song: 6.75\n"
     ]
    }
   ],
   "source": [
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "songs = len(data)\n",
    "annotations = sum(len(s.get('annotations', [])) for s in data)\n",
    "print('Songs:', songs)\n",
    "print('Annotations:', annotations)\n",
    "print('Avg annotations per song:', round(annotations / songs, 2) if songs else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: 22220\n",
      "Using subset: 2000\n"
     ]
    }
   ],
   "source": [
    "fragments = []\n",
    "annotations = []\n",
    "metadata = []\n",
    "\n",
    "for song in data:\n",
    "    for ann in song.get('annotations', []):\n",
    "        fragments.append(ann.get('fragment', ''))\n",
    "        annotations.append(ann.get('annotation', ''))\n",
    "        metadata.append({\n",
    "            'artist': song.get('artist', ''),\n",
    "            'title': song.get('title', ''),\n",
    "            'votes': ann.get('votes', 0),\n",
    "        })\n",
    "\n",
    "print('Pairs:', len(fragments))\n",
    "\n",
    "MAX_EXAMPLES = 2000  # set None for full run\n",
    "if MAX_EXAMPLES:\n",
    "    import random\n",
    "    idx = list(range(len(fragments)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(idx)\n",
    "    idx = idx[:MAX_EXAMPLES]\n",
    "    fragments = [fragments[i] for i in idx]\n",
    "    annotations = [annotations[i] for i in idx]\n",
    "    metadata = [metadata[i] for i in idx]\n",
    "    print('Using subset:', len(fragments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge_score import rouge_scorer\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, fragments, annotations, metadata, alpha=0.5, model_name='paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.fragments = fragments\n",
    "        self.annotations = annotations\n",
    "        self.metadata = metadata\n",
    "        self.alpha = alpha\n",
    "        self.tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2), lowercase=True)\n",
    "        self.tfidf_vectors = self.tfidf.fit_transform(self.fragments)\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.embeddings = self.model.encode(self.fragments, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "    def find_similar(self, query, top_k=3):\n",
    "        query_tfidf = self.tfidf.transform([query])\n",
    "        tfidf_sims = cosine_similarity(query_tfidf, self.tfidf_vectors)[0]\n",
    "        query_emb = self.model.encode([query], convert_to_numpy=True)\n",
    "        sbert_sims = cosine_similarity(query_emb, self.embeddings)[0]\n",
    "        hybrid_sims = (1 - self.alpha) * tfidf_sims + self.alpha * sbert_sims\n",
    "        top_indices = np.argsort(hybrid_sims)[-top_k:][::-1]\n",
    "        return [\n",
    "            {\n",
    "                'fragment': self.fragments[idx],\n",
    "                'annotation': self.annotations[idx],\n",
    "                'similarity': float(hybrid_sims[idx]),\n",
    "                'tfidf_sim': float(tfidf_sims[idx]),\n",
    "                'sbert_sim': float(sbert_sims[idx]),\n",
    "                'artist': self.metadata[idx]['artist'],\n",
    "                'title': self.metadata[idx]['title'],\n",
    "                'votes': self.metadata[idx]['votes'],\n",
    "            }\n",
    "            for idx in top_indices\n",
    "        ]\n",
    "\n",
    "def evaluate_hybrid(fragments, annotations, metadata, alpha=0.5, model_name='paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "    retriever = HybridRetriever(fragments, annotations, metadata, alpha=alpha, model_name=model_name)\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    similarities = []\n",
    "\n",
    "    for i, fragment in enumerate(fragments):\n",
    "        query_tfidf = retriever.tfidf_vectors[i]\n",
    "        tfidf_sims = cosine_similarity(query_tfidf, retriever.tfidf_vectors)[0]\n",
    "        sbert_sims = cosine_similarity(retriever.embeddings[i:i+1], retriever.embeddings)[0]\n",
    "        hybrid_sims = (1 - alpha) * tfidf_sims + alpha * sbert_sims\n",
    "        hybrid_sims[i] = -1e9\n",
    "        top_indices = np.argsort(hybrid_sims)[-3:][::-1]\n",
    "\n",
    "        predicted = annotations[top_indices[0]]\n",
    "        true_annotation = annotations[i]\n",
    "\n",
    "        predictions.append(predicted)\n",
    "        references.append(true_annotation)\n",
    "        similarities.append(hybrid_sims[top_indices[0]])\n",
    "\n",
    "        if predicted == true_annotation:\n",
    "            correct_top1 += 1\n",
    "        if true_annotation in [annotations[idx] for idx in top_indices]:\n",
    "            correct_top3 += 1\n",
    "\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "    bleu = corpus_bleu(predictions, [[r] for r in references])\n",
    "\n",
    "    return {\n",
    "        'method': f'Hybrid (alpha={alpha})',\n",
    "        'top1_accuracy': correct_top1 / len(fragments) if fragments else 0.0,\n",
    "        'top3_accuracy': correct_top3 / len(fragments) if fragments else 0.0,\n",
    "        'avg_similarity': float(np.mean(similarities)) if similarities else 0.0,\n",
    "        'rouge1': float(np.mean(rouge_scores['rouge1'])) if rouge_scores['rouge1'] else 0.0,\n",
    "        'rouge2': float(np.mean(rouge_scores['rouge2'])) if rouge_scores['rouge2'] else 0.0,\n",
    "        'rougeL': float(np.mean(rouge_scores['rougeL'])) if rouge_scores['rougeL'] else 0.0,\n",
    "        'bleu': bleu.score,\n",
    "        'total_examples': len(fragments),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha3.json\n",
      "alpha 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha5.json\n",
      "alpha 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:01<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha7.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "hybrid_results = []\n",
    "for alpha in [0.3, 0.5, 0.7]:\n",
    "    print('alpha', alpha)\n",
    "    res = evaluate_hybrid(fragments, annotations, metadata, alpha=alpha)\n",
    "    hybrid_results.append(res)\n",
    "    out_path = Path('..') / 'data' / f'hybrid_results_alpha{int(alpha*10)}.json'\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(res, f, ensure_ascii=False, indent=2)\n",
    "    print('Saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (GPU recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 29.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha3.json\n",
      "alpha 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha5.json\n",
      "alpha 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/hybrid_results_alpha7.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "hybrid_results = []\n",
    "for alpha in [0.3, 0.5, 0.7]:\n",
    "    print('alpha', alpha)\n",
    "    res = evaluate_hybrid(fragments, annotations, metadata, alpha=alpha)\n",
    "    hybrid_results.append(res)\n",
    "    out_path = Path('..') / 'data' / f'hybrid_results_alpha{int(alpha*10)}.json'\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(res, f, ensure_ascii=False, indent=2)\n",
    "    print('Saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:02<00:00, 29.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fragment': 'Город под подошвой\\n Город под подошвой — этот город под подошвой',\n",
       "  'annotation': '«Город под подошвой» — песня российского рэпера Оксимирона (Oxxxymiron).',\n",
       "  'similarity': 0.7939328427070708,\n",
       "  'tfidf_sim': 0.7662352075088681,\n",
       "  'sbert_sim': 0.8216304779052734,\n",
       "  'artist': 'CMH',\n",
       "  'title': 'GAZZ',\n",
       "  'votes': 3},\n",
       " {'fragment': 'Еду в центр, это город дорог',\n",
       "  'annotation': 'Игра слов отсылает нас к треку группы CENTR – Город дорог',\n",
       "  'similarity': 0.6143498246787367,\n",
       "  'tfidf_sim': 0.5424553404089566,\n",
       "  'sbert_sim': 0.6862443089485168,\n",
       "  'artist': 'OG Buda',\n",
       "  'title': 'Дзагоев (Dzagoev)',\n",
       "  'votes': 3}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = HybridRetriever(fragments, annotations, metadata, alpha=0.5)\n",
    "retriever.find_similar('Я вижу город под подошвой', top_k=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
