{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EDA: Russian Song Lyrics Dataset\n",
    "\n",
    "Exploratory Data Analysis для датасета русских песен\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Загружаем данные\n",
    "df = pd.read_csv('../data/russian_song_lyrics.csv')\n",
    "print(f\" Загружено {len(df):,} песен\")\n",
    "print(f\" Колонки: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Общая статистика\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Информация о датасете ===\")\n",
    "print(f\"Всего песен: {len(df):,}\")\n",
    "print(f\"Уникальных артистов: {df['artist'].nunique():,}\")\n",
    "print(f\"Период: {df['year'].min():.0f} - {df['year'].max():.0f}\")\n",
    "print(f\"\\nПропущенные значения:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Распределение по жанрам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение жанров\n",
    "genre_counts = df['tag'].value_counts()\n",
    "print(\"Топ жанров:\")\n",
    "print(genre_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "genre_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('Распределение песен по жанрам', fontsize=14)\n",
    "plt.xlabel('Жанр')\n",
    "plt.ylabel('Количество песен')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Rap составляет {genre_counts['rap']/len(df)*100:.1f}% датасета\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Топ артисты (RAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем только рэп\n",
    "rap_df = df[df['tag'] == 'rap'].copy()\n",
    "print(f\" Рэп песен: {len(rap_df):,}\")\n",
    "\n",
    "# Топ артисты\n",
    "top_artists = rap_df['artist'].value_counts().head(20)\n",
    "print(\"\\n=== Топ 20 рэп-артистов ===\")\n",
    "for i, (artist, count) in enumerate(top_artists.items(), 1):\n",
    "    print(f\"{i:2d}. {artist:40s} - {count:4d} песен\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_artists.plot(kind='barh', color='coral')\n",
    "plt.title('Топ 20 рэп-артистов по количеству песен', fontsize=14)\n",
    "plt.xlabel('Количество песен')\n",
    "plt.ylabel('Артист')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проблемы с форматированием артистов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ проблем с именами\n",
    "print(\"=== Проблемы форматирования ===\")\n",
    "\n",
    "# Артисты с лишними пробелами\n",
    "artists_with_spaces = rap_df[rap_df['artist'].str.startswith(' ')]['artist'].unique()\n",
    "print(f\"\\nАртисты с лишними пробелами: {len(artists_with_spaces)}\")\n",
    "print(\"Примеры:\")\n",
    "for artist in list(artists_with_spaces)[:10]:\n",
    "    print(f'  \"{artist}\"')\n",
    "\n",
    "# Артисты со скобками\n",
    "artists_with_brackets = rap_df[rap_df['artist'].str.contains(r'\\(.*\\)', na=False)]['artist'].unique()\n",
    "print(f\"\\nАртисты со скобками: {len(artists_with_brackets)}\")\n",
    "print(\"Примеры:\")\n",
    "for artist in list(artists_with_brackets)[:10]:\n",
    "    print(f'  \"{artist}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Целевые артисты для сбора аннотаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Известные русские рэп-артисты\n",
    "target_artists_search = {\n",
    "    'Oxxxymiron': ['Oxxxymiron', 'Oxxxy'],\n",
    "    'FACE': ['FACE', 'Face'],\n",
    "    'PHARAOH': ['PHARAOH', 'Pharaoh'],\n",
    "    'Miyagi': ['Miyagi'],\n",
    "    'Скриптонит': ['Scriptonite', 'Skryptonite'],\n",
    "    'Баста': ['Basta', 'Баста'],\n",
    "    'Гуф': ['Guf', 'Гуф'],\n",
    "    'Noize MC': ['Noize MC'],\n",
    "    'Каста': ['Kasta', 'Каста'],\n",
    "    'Замай': ['Zamay', 'Замай'],\n",
    "    'Слава КПСС': ['Slava KPSS'],\n",
    "    'Элджей': ['Eldzhey', 'Элджей'],\n",
    "    'Johnyboy': ['Johnyboy'],\n",
    "}\n",
    "\n",
    "print(\"=== Целевые артисты для сбора аннотаций ===\")\n",
    "target_stats = []\n",
    "\n",
    "for artist_name, search_terms in target_artists_search.items():\n",
    "    # Ищем по всем вариантам\n",
    "    mask = rap_df['artist'].str.contains('|'.join(search_terms), case=False, na=False, regex=True)\n",
    "    matches = rap_df[mask]\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        actual_name = matches['artist'].value_counts().index[0]\n",
    "        count = len(matches)\n",
    "        target_stats.append({\n",
    "            'artist': artist_name,\n",
    "            'actual_name': actual_name,\n",
    "            'songs': count\n",
    "        })\n",
    "        print(f\" {artist_name:20s} - {count:4d} песен (как '{actual_name}')\")\n",
    "\n",
    "target_df = pd.DataFrame(target_stats)\n",
    "print(f\"\\n Всего найдено {len(target_df)} целевых артистов\")\n",
    "print(f\" Всего песен: {target_df['songs'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ текстов песен\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по длине текстов\n",
    "rap_df['lyrics_length'] = rap_df['lyrics'].fillna('').str.len()\n",
    "rap_df['lyrics_words'] = rap_df['lyrics'].fillna('').str.split().str.len()\n",
    "\n",
    "print(\"=== Статистика по текстам ===\")\n",
    "print(f\"Средняя длина текста: {rap_df['lyrics_length'].mean():.0f} символов\")\n",
    "print(f\"Среднее количество слов: {rap_df['lyrics_words'].mean():.0f} слов\")\n",
    "print(f\"\\nКвартили длины (слова):\")\n",
    "print(rap_df['lyrics_words'].describe())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Распределение длины\n",
    "axes[0].hist(rap_df['lyrics_words'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Количество слов')\n",
    "axes[0].set_ylabel('Частота')\n",
    "axes[0].set_title('Распределение длины текстов')\n",
    "axes[0].axvline(rap_df['lyrics_words'].median(), color='red', linestyle='--', label='Медиана')\n",
    "axes[0].legend()\n",
    "\n",
    "# Boxplot\n",
    "axes[1].boxplot(rap_df['lyrics_words'].dropna())\n",
    "axes[1].set_ylabel('Количество слов')\n",
    "axes[1].set_title('Boxplot длины текстов')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Экспорт целевых артистов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем список целевых артистов для сборщика\n",
    "target_df.to_json('../data/target_artists.json', orient='records', force_ascii=False, indent=2)\n",
    "print(\" Сохранено в data/target_artists.json\")\n",
    "print(f\"\\n Готово для сбора аннотаций с {len(target_df)} артистов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Пропуски и качество данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = df.isnull().mean().sort_values(ascending=False)\n",
    "missing_ratio = missing_ratio[missing_ratio > 0]\n",
    "print('Колонки с пропусками:')\n",
    "print(missing_ratio.apply(lambda x: f'{x*100:.1f}%'))\n",
    "\n",
    "if not missing_ratio.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    missing_ratio.sort_values().plot(kind='barh', color='slategray')\n",
    "    plt.title('Доля пропусков по колонкам')\n",
    "    plt.xlabel('Доля пропусков')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Языки в датасете\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['language', 'language_cld3', 'language_ft']:\n",
    "    if col in df.columns:\n",
    "        print(f'=== {col} ===')\n",
    "        print(df[col].value_counts().head(10))\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        df[col].value_counts().head(10).plot(kind='bar', color='teal')\n",
    "        plt.title(f'Top-10 значений {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Количество')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Распределение по годам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'year' in rap_df.columns:\n",
    "    years = pd.to_numeric(rap_df['year'], errors='coerce').dropna().astype(int)\n",
    "    if not years.empty:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(years, bins=30, color='steelblue', edgecolor='black')\n",
    "        plt.title('Распределение рэп-песен по годам')\n",
    "        plt.xlabel('Год')\n",
    "        plt.ylabel('Количество песен')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Просмотры (views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'views' in df.columns:\n",
    "    df['views_num'] = pd.to_numeric(df['views'], errors='coerce')\n",
    "    print('Просмотры (описательная статистика):')\n",
    "    print(df['views_num'].describe())\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(np.log1p(df['views_num'].dropna()), bins=50, color='purple', alpha=0.7)\n",
    "    plt.title('Распределение просмотров (log1p)')\n",
    "    plt.xlabel('log1p(views)')\n",
    "    plt.ylabel('Количество песен')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    top_songs = df[['artist', 'title', 'views_num']].sort_values('views_num', ascending=False).head(10)\n",
    "    print('Топ-10 песен по просмотрам:')\n",
    "    print(top_songs.to_string(index=False))\n",
    "\n",
    "    top_artists_views = df.groupby('artist')['views_num'].sum().sort_values(ascending=False).head(10)\n",
    "    print('Топ-10 артистов по суммарным просмотрам:')\n",
    "    print(top_artists_views)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Дубликаты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups_artist_title = df.duplicated(subset=['artist', 'title']).sum()\n",
    "dups_lyrics = df['lyrics'].fillna('').duplicated().sum()\n",
    "print(f'Дубликаты (artist,title): {dups_artist_title:,}')\n",
    "print(f'Дубликаты lyrics: {dups_lyrics:,}')\n",
    "\n",
    "if dups_artist_title > 0:\n",
    "    dup_rows = df[df.duplicated(subset=['artist', 'title'], keep=False)].head(10)\n",
    "    print('Примеры дубликатов artist/title:')\n",
    "    print(dup_rows[['artist', 'title', 'year']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Связь длины текста и просмотров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'views_num' in df.columns and 'lyrics' in df.columns:\n",
    "    temp = df.copy()\n",
    "    temp['lyrics_words'] = temp['lyrics'].fillna('').str.split().str.len()\n",
    "    temp = temp.dropna(subset=['views_num'])\n",
    "    if len(temp) > 0:\n",
    "        corr = temp['views_num'].corr(temp['lyrics_words'])\n",
    "        print(f'Корреляция views и длины текста (слова): {corr:.3f}')\n",
    "        sample = temp.sample(n=min(2000, len(temp)), random_state=42)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.scatter(sample['lyrics_words'], np.log1p(sample['views_num']), alpha=0.3, s=10)\n",
    "        plt.xlabel('Длина текста (слова)')\n",
    "        plt.ylabel('log1p(views)')\n",
    "        plt.title('Длина текста vs просмотры')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Участники (features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'features' in df.columns:\n",
    "    feats = df['features'].fillna('')\n",
    "    feats = feats[feats.str.len() > 0]\n",
    "    if len(feats) > 0:\n",
    "        all_feats = []\n",
    "        for row in feats:\n",
    "            parts = [p.strip() for p in re.split(r'[,&/;]\\s*', str(row)) if p.strip()]\n",
    "            all_feats.extend(parts)\n",
    "        feat_counts = pd.Series(all_feats).value_counts().head(20)\n",
    "        print('Топ фичерингов:')\n",
    "        print(feat_counts)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        feat_counts[::-1].plot(kind='barh', color='olive')\n",
    "        plt.title('Топ-20 фичерингов')\n",
    "        plt.xlabel('Количество')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Аналитика аннотаций"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "ann_path = Path('..') / 'data' / 'annotations_dataset_full.json'\n",
    "if not ann_path.exists():\n",
    "    ann_path = Path('..') / 'data' / 'annotations_dataset_new.json'\n",
    "\n",
    "if ann_path.exists():\n",
    "    with open(ann_path, 'r', encoding='utf-8') as f:\n",
    "        ann_data = json.load(f)\n",
    "\n",
    "    total_songs = len(ann_data)\n",
    "    total_anns = sum(len(s.get('annotations', [])) for s in ann_data)\n",
    "    print('Annotations dataset:', ann_path)\n",
    "    print('Songs:', total_songs)\n",
    "    print('Annotations:', total_anns)\n",
    "    print('Avg annotations per song:', round(total_anns / total_songs, 2) if total_songs else 0)\n",
    "\n",
    "    rows = []\n",
    "    for song in ann_data:\n",
    "        artist = song.get('artist', '')\n",
    "        title = song.get('title', '')\n",
    "        for ann in song.get('annotations', []):\n",
    "            rows.append({\n",
    "                'artist': artist,\n",
    "                'title': title,\n",
    "                'fragment': ann.get('fragment', ''),\n",
    "                'annotation': ann.get('annotation', ''),\n",
    "                'votes': ann.get('votes', 0),\n",
    "            })\n",
    "\n",
    "    ann_df = pd.DataFrame(rows)\n",
    "    ann_df['fragment_words'] = ann_df['fragment'].fillna('').str.split().str.len()\n",
    "    ann_df['annotation_words'] = ann_df['annotation'].fillna('').str.split().str.len()\n",
    "\n",
    "    print('\\nFragment length (words):')\n",
    "    print(ann_df['fragment_words'].describe())\n",
    "    print('\\nAnnotation length (words):')\n",
    "    print(ann_df['annotation_words'].describe())\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(ann_df['fragment_words'], bins=50, color='steelblue', edgecolor='black')\n",
    "    plt.title('Fragment length distribution (words)')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(ann_df['annotation_words'], bins=50, color='coral', edgecolor='black')\n",
    "    plt.title('Annotation length distribution (words)')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if 'votes' in ann_df.columns:\n",
    "        print('\\nVotes stats:')\n",
    "        print(ann_df['votes'].describe())\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        ann_df['votes'].plot(kind='hist', bins=30, color='slategray', edgecolor='black')\n",
    "        plt.title('Votes distribution')\n",
    "        plt.xlabel('Votes')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    top_artists = ann_df.groupby('artist').size().sort_values(ascending=False).head(10)\n",
    "    print('\\nTop-10 artists by annotation count:')\n",
    "    print(top_artists)\n",
    "\n",
    "    top_votes = ann_df.sort_values('votes', ascending=False).head(5)\n",
    "    print('\\nTop-5 annotations by votes:')\n",
    "    print(top_votes[['artist', 'title', 'fragment', 'votes']].to_string(index=False))\n",
    "else:\n",
    "    print('Annotations dataset not found:', ann_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": "if ann_path.exists():\n    print('='*70)\n    print('РЕКОМЕНДАЦИИ ПО ОЧИСТКЕ ДАННЫХ')\n    print('='*70)\n    \n    # 1. Дубликаты\n    unique_before = len(ann_df)\n    ann_df_clean = ann_df.drop_duplicates(subset=['fragment', 'annotation'])\n    unique_after = len(ann_df_clean)\n    removed_dups = unique_before - unique_after\n    \n    print(f'\\n1⃣ Удаление дубликатов:')\n    print(f'   Было: {unique_before:,} аннотаций')\n    print(f'   Стало: {unique_after:,} аннотаций')\n    print(f'   Удалено: {removed_dups:,} ({removed_dups/unique_before*100:.1f}%)')\n    \n    # 2. Пустые фрагменты/аннотации\n    empty_fragments = (ann_df_clean['fragment'].str.strip() == '').sum()\n    empty_annotations = (ann_df_clean['annotation'].str.strip() == '').sum()\n    \n    print(f'\\n2⃣ Пустые значения:')\n    print(f'   Пустых фрагментов: {empty_fragments}')\n    print(f'   Пустых аннотаций: {empty_annotations}')\n    \n    ann_df_clean = ann_df_clean[\n        (ann_df_clean['fragment'].str.strip() != '') & \n        (ann_df_clean['annotation'].str.strip() != '')\n    ]\n    \n    # 3. Слишком короткие\n    min_words = 3\n    too_short = (ann_df_clean['fragment_words'] < min_words).sum()\n    \n    print(f'\\n3⃣ Короткие фрагменты (< {min_words} слов):')\n    print(f'   Количество: {too_short} ({too_short/len(ann_df_clean)*100:.1f}%)')\n    \n    # 4. Слишком длинные выбросы\n    q99_fragment = ann_df_clean['fragment_words'].quantile(0.99)\n    q99_annotation = ann_df_clean['annotation_words'].quantile(0.99)\n    \n    outliers_fragment = (ann_df_clean['fragment_words'] > q99_fragment).sum()\n    outliers_annotation = (ann_df_clean['annotation_words'] > q99_annotation).sum()\n    \n    print(f'\\n4⃣ Выбросы (> 99 перцентиль):')\n    print(f'   Фрагменты > {q99_fragment:.0f} слов: {outliers_fragment}')\n    print(f'   Аннотации > {q99_annotation:.0f} слов: {outliers_annotation}')\n    \n    # Итоговая рекомендация\n    print(f'\\n' + '='*70)\n    print(' ИТОГОВАЯ РЕКОМЕНДАЦИЯ:')\n    print('='*70)\n    print(f' Исходный датасет: {unique_before:,} аннотаций')\n    print(f' После очистки: {len(ann_df_clean):,} аннотаций')\n    print(f' Сохранено: {len(ann_df_clean)/unique_before*100:.1f}%')\n    print(f'\\nРекомендуется:')\n    print(f'  1. Удалить дубликаты: -{removed_dups:,}')\n    print(f'  2. Удалить пустые: -{empty_fragments + empty_annotations}')\n    print(f'  3. Опционально: фильтровать короткие (< {min_words} слов)')\n    print(f'  4. Опционально: обрезать выбросы (> 99 перцентиль)')\n    \n    # Сохранить очищенный датасет\n    print(f'\\n Для сохранения очищенного датасета используйте:')\n    print(f'   cleaned_data = ann_df_clean.to_dict(\"records\")')\n    print(f'   # Затем сгруппировать обратно по песням и сохранить в JSON')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 19. Рекомендации по очистке данных",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if ann_path.exists():\n    print('='*70)\n    print('КОРРЕЛЯЦИОННЫЙ АНАЛИЗ')\n    print('='*70)\n    \n    # Корреляция\n    corr = ann_df[['fragment_words', 'annotation_words', 'votes']].corr()\n    print('\\n Корреляционная матрица:')\n    print(corr)\n    \n    # Визуализация корреляции\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Heatmap\n    ax1 = axes[0]\n    sns.heatmap(corr, annot=True, fmt='.3f', cmap='coolwarm', center=0, \n                square=True, ax=ax1, cbar_kws={'label': 'Correlation'})\n    ax1.set_title('Корреляционная матрица', fontsize=14)\n    \n    # Scatter: fragment vs annotation length\n    ax2 = axes[1]\n    sample = ann_df.sample(n=min(2000, len(ann_df)), random_state=42)\n    ax2.scatter(sample['fragment_words'], sample['annotation_words'], \n                alpha=0.3, s=20, c=sample['votes'], cmap='viridis')\n    ax2.set_xlabel('Длина фрагмента (слова)', fontsize=12)\n    ax2.set_ylabel('Длина аннотации (слова)', fontsize=12)\n    ax2.set_title('Связь длины фрагмента и аннотации\\n(цвет = votes)', fontsize=12)\n    ax2.grid(alpha=0.3)\n    \n    # Добавим линию тренда\n    z = np.polyfit(sample['fragment_words'], sample['annotation_words'], 1)\n    p = np.poly1d(z)\n    ax2.plot(sample['fragment_words'].sort_values(), \n             p(sample['fragment_words'].sort_values()), \n             \"r--\", alpha=0.8, linewidth=2, label=f'y={z[0]:.2f}x+{z[1]:.2f}')\n    ax2.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Статистические выводы\n    corr_val = ann_df['fragment_words'].corr(ann_df['annotation_words'])\n    print(f'\\n Корреляция между длиной фрагмента и аннотации: {corr_val:.3f}')\n    \n    if corr_val > 0.3:\n        print('    Умеренная положительная корреляция - длинные фрагменты имеют более длинные аннотации')\n    elif corr_val > 0.1:\n        print('    Слабая корреляция - связь не очевидна')\n    else:\n        print('    Корреляция отсутствует')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 18. Корреляция длины фрагмента и аннотации",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if ann_path.exists():\n    print('='*70)\n    print('АНАЛИЗ ПО АРТИСТАМ')\n    print('='*70)\n    \n    # Статистика по артистам\n    artist_stats = ann_df.groupby('artist').agg({\n        'fragment': 'count',\n        'votes': ['sum', 'mean'],\n        'fragment_words': 'mean',\n        'annotation_words': 'mean'\n    }).round(2)\n    \n    artist_stats.columns = ['Annotations', 'Total_Votes', 'Avg_Votes', 'Avg_Fragment_Words', 'Avg_Annotation_Words']\n    artist_stats = artist_stats.sort_values('Annotations', ascending=False)\n    \n    print(f'\\n Топ-20 артистов по количеству аннотаций:')\n    print(artist_stats.head(20).to_string())\n    \n    # Топ по аннотациям\n    top20_artists = artist_stats.head(20)\n    \n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    # 1. Количество аннотаций\n    ax1 = axes[0, 0]\n    top20_artists['Annotations'].plot(kind='barh', ax=ax1, color='steelblue')\n    ax1.set_title('Топ-20 артистов: Количество аннотаций', fontsize=12)\n    ax1.set_xlabel('Количество аннотаций')\n    ax1.invert_yaxis()\n    \n    # 2. Средняя длина фрагмента\n    ax2 = axes[0, 1]\n    top20_artists['Avg_Fragment_Words'].plot(kind='barh', ax=ax2, color='coral')\n    ax2.set_title('Топ-20: Средняя длина фрагмента (слова)', fontsize=12)\n    ax2.set_xlabel('Средняя длина (слова)')\n    ax2.invert_yaxis()\n    \n    # 3. Средняя длина аннотации\n    ax3 = axes[1, 0]\n    top20_artists['Avg_Annotation_Words'].plot(kind='barh', ax=ax3, color='lightgreen')\n    ax3.set_title('Топ-20: Средняя длина аннотации (слова)', fontsize=12)\n    ax3.set_xlabel('Средняя длина (слова)')\n    ax3.invert_yaxis()\n    \n    # 4. Средний рейтинг (votes)\n    ax4 = axes[1, 1]\n    top20_artists['Avg_Votes'].plot(kind='barh', ax=ax4, color='gold')\n    ax4.set_title('Топ-20: Средний рейтинг аннотаций', fontsize=12)\n    ax4.set_xlabel('Средний votes')\n    ax4.invert_yaxis()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Уникальные артисты\n    print(f'\\n Уникальных артистов: {ann_df[\"artist\"].nunique()}')\n    print(f' Уникальных песен: {ann_df.groupby([\"artist\", \"title\"]).ngroups}')\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 17. Анализ по артистам - аннотации",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if ann_path.exists():\n    print('='*70)\n    print('АНАЛИЗ ДУБЛИКАТОВ')\n    print('='*70)\n    \n    # Проверяем дубликаты по fragment + annotation\n    ann_df['pair_key'] = ann_df['fragment'] + '|||' + ann_df['annotation']\n    \n    duplicates = ann_df['pair_key'].duplicated().sum()\n    unique_pairs = ann_df['pair_key'].nunique()\n    \n    print(f'\\n Статистика дубликатов:')\n    print(f'  Всего аннотаций: {len(ann_df):,}')\n    print(f'  Уникальных пар (fragment+annotation): {unique_pairs:,}')\n    print(f'  Дубликатов: {duplicates:,} ({duplicates/len(ann_df)*100:.1f}%)')\n    \n    # Топ дубликаты\n    dup_counts = ann_df['pair_key'].value_counts()\n    top_dups = dup_counts[dup_counts > 1].head(10)\n    \n    if len(top_dups) > 0:\n        print(f'\\n Топ-10 самых частых дубликатов:')\n        for i, (key, count) in enumerate(top_dups.items(), 1):\n            fragment, annotation = key.split('|||')\n            print(f'\\n{i}. Повторяется {count} раз')\n            print(f'   Fragment: \"{fragment[:80]}...\"')\n            print(f'   Annotation: \"{annotation[:80]}...\"')\n        \n        # Визуализация\n        plt.figure(figsize=(10, 6))\n        top_dups.plot(kind='bar', color='salmon', edgecolor='black')\n        plt.title('Топ-10 дубликатов аннотаций', fontsize=14)\n        plt.xlabel('Индекс дубликата')\n        plt.ylabel('Количество повторений')\n        plt.xticks([])\n        plt.tight_layout()\n        plt.show()\n        \n        # Распределение количества дубликатов\n        dup_distribution = dup_counts.value_counts().sort_index()\n        print(f'\\n Распределение дубликатов:')\n        print(f'  Уникальных (1 копия): {dup_distribution.get(1, 0):,}')\n        print(f'  Дубликаты (2+ копий): {dup_distribution[dup_distribution.index > 1].sum():,}')\n        \n        plt.figure(figsize=(10, 5))\n        dup_distribution[dup_distribution.index <= 20].plot(kind='bar', color='teal', edgecolor='black')\n        plt.title('Распределение числа копий аннотаций', fontsize=14)\n        plt.xlabel('Количество копий')\n        plt.ylabel('Количество аннотаций')\n        plt.tight_layout()\n        plt.show()\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 16. Детальный анализ аннотаций - Дубликаты",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}